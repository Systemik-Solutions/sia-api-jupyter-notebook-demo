{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import necessary library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import certifi\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.ticker import FixedLocator\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Replace with your API key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = \"255446bcdde7ca9fe776258d09e8411bbb8d1cade2ebd6aba440f80f6817c3fd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**EX3. Frequencies of HAS and HATH in the plays**\n",
    "\n",
    "**Text set = Shakespeare 20 for demos**  \n",
    "**Segment by text**  \n",
    "**Include metadata in output**  \n",
    "**Words unsorted – HAS HATH**  \n",
    "**Output – choose proportions**  \n",
    "**Transform and chart – sort by DATE, plot HAS and HATH as lines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Frequencies of HAS and HATH in the plays \n",
    "\n",
    "# Text set = Shakespeare 20 for demos \n",
    "# Segment by text \n",
    "# Include metadata in output \n",
    "# Words unsorted – HAS HATH \n",
    "# Output – choose proportions \n",
    "# Transform and chart – sort by DATE, plot HAS and HATH as lines \n",
    "\n",
    "# Replace with your actual text set ID \n",
    "textset_id = 86 \n",
    "\n",
    "#Character to exlude from search\n",
    "excludeWords = [\"[\",\"\\\\\", \"]\", \"_\", \"`\", \"!\", \"\\\"\", \"#\", \"%\", \"'\", \"(\", \")\", \"+\", \",\", \"-\", \"–\", \".\", \"/\", \":\", \";\", \"{\", \"|\", \"}\", \"=\", \"~\", \"?\" ]\n",
    "\n",
    "request_url = \"https://sia.ardc-hdcl-sia-iaw.cloud.edu.au/api/v1/word-frequencies\"\n",
    "character_parts_request = {\n",
    "    'textSet': textset_id,\n",
    "    'option': {\n",
    "        'blockMethod' : 0,         #Segment by text\n",
    "        'showMetadata' : True,\n",
    "        'outputSize': 1000 , \n",
    "        # 'outputSpecialWords' : [\"has\",\"hath\"],\n",
    "        # 'outputSpecialWordsOption' : 0,\n",
    "        'excludeWords': excludeWords,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Make API request\n",
    "response = requests.post(request_url, json=character_parts_request, headers={\"X-API-KEY\": api_key}, timeout=1200)\n",
    "\n",
    "special_word_count_by_year = {\"has\": {}, \"hath\": {}}\n",
    "total_word_count_by_year = {}\n",
    "\n",
    "# Handle the response\n",
    "if response.status_code == 200:\n",
    "    response_data = response.json()\n",
    "    blocks = response_data.get(\"blocks\", [])\n",
    "    \n",
    "\n",
    "    for block in blocks:\n",
    "        name = block.get(\"name\", \"\")\n",
    "        freqs = block.get(\"frequencies\", [])\n",
    "        \n",
    "        # Extract year from name\n",
    "        year = block.get('metadata').get('Date_of_publication')\n",
    "        \n",
    "        name.split(\"_\")[-1].split(\" \")[0]\n",
    "        \n",
    "        for freq in freqs:\n",
    "            word = freq.get(\"word\", \"\")\n",
    "            value = freq.get(\"value\", 0)\n",
    "            \n",
    "            if word.lower() == \"has\":\n",
    "                special_word_count_by_year[\"has\"][year] = special_word_count_by_year[\"has\"].get(year, 0) + value\n",
    "            elif word.lower() == \"hath\":\n",
    "                special_word_count_by_year[\"hath\"][year] = special_word_count_by_year[\"hath\"].get(year, 0) + value\n",
    "                \n",
    "            total_word_count_by_year[year] = total_word_count_by_year.get(year, 0) + value\n",
    "\n",
    "    # Sort by Year\n",
    "    sorted_years = sorted(set(special_word_count_by_year[\"has\"].keys()) | set(special_word_count_by_year[\"hath\"].keys()))\n",
    "    has_counts = [(special_word_count_by_year[\"has\"].get(year, 0) / total_word_count_by_year.get(year, 1)) * 100 for year in sorted_years]\n",
    "    hath_counts = [(special_word_count_by_year[\"hath\"].get(year, 0) / total_word_count_by_year.get(year, 1)) * 100 for year in sorted_years]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(sorted_years, has_counts, label='HAS', marker='o')\n",
    "    plt.plot(sorted_years, hath_counts, label='HATH', marker='o')\n",
    "    plt.scatter(sorted_years, has_counts)\n",
    "    plt.scatter(sorted_years, hath_counts)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.title('Percentage of \"HAS\" and \"HATH\" over years')\n",
    "\n",
    "    y_ticks = plt.gca().get_yticks()\n",
    "    plt.gca().yaxis.set_major_locator(FixedLocator(y_ticks))\n",
    "    plt.gca().set_yticklabels(['{:.2f}%'.format(y) for y in y_ticks])\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Metadata\n",
    "    html = '<h2>Metadata</h2>'\n",
    "    html += '<div style=\"overflow: auto; max-height: 500px; margin-top: 40px;\">'\n",
    "    html += '<table border=\"1\">'\n",
    "     # Adding the table header for Metadata\n",
    "    if blocks:\n",
    "        first_metadata = blocks[0].get(\"metadata\", {})\n",
    "        html += '<tr>'\n",
    "        for header in first_metadata.keys():\n",
    "            html += f'<th style=\"white-space: nowrap;\">{header}</th>'\n",
    "        html += '</tr>'\n",
    "        \n",
    "        # Adding Metadata data rows\n",
    "        for block in blocks:\n",
    "            metadata = block.get(\"metadata\", {})\n",
    "            html += '<tr>'\n",
    "            for key in first_metadata.keys():  # Ensure the same order as headers\n",
    "                html += f'<td style=\"white-space: nowrap;\">{metadata.get(key, \"N/A\")}</td>'\n",
    "            html += '</tr>'\n",
    "        \n",
    "    html += '</table></div>'\n",
    "    \n",
    "    # Display the table\n",
    "    display(HTML(html))\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(f\"Failed: {response.status_code} {response.reason}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
